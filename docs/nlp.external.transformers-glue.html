---

title: Text Classification with Transformers (Intermediate)


keywords: fastai
sidebar: home_sidebar

summary: "Fine-tuning pre-trained LM from HuggingFace model hub on GLUE benchmark"
description: "Fine-tuning pre-trained LM from HuggingFace model hub on GLUE benchmark"
nb_path: "nbs/07_nlp.external.transformers-glue.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/07_nlp.external.transformers-glue.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">concatenate_datasets</span>
<span class="kn">from</span> <span class="nn">inspect</span> <span class="kn">import</span> <span class="n">signature</span>
<span class="kn">import</span> <span class="nn">gc</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea output_execute_result">
<hr>
<p>This article is also a Jupyter Notebook available to be run from the top down. There
will be code snippets that you can then run in any environment.</p>
<p>Below are the versions of <code>fastai</code>, <code>fastcore</code>, <code>transformers</code>, and <code>datasets</code> currently running at the time of writing this:</p>
<ul>
<li><code>fastai</code> : 2.3.1 </li>
<li><code>fastcore</code> : 1.3.19 </li>
<li><code>transformers</code> : 4.6.0 </li>
<li><code>datasets</code> : 1.6.1 </li>
</ul>
<hr>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup"> </a></h2><p>In this notebook we will look at how to conbine the power of <a href="https://huggingface.co/">HuggingFace</a> with great flexibility of <a href="https://www.fast.ai/">fastai</a>. For this purpose we will be finetuning <code>distilroberta-base</code> on The <a href="https://gluebenchmark.com/">General Language Understanding Evaluation(GLUE) benchmark</a> tasks.</p>
<p>To give you a grasp on what are we dealing with, here is a brief summary of GLUE tasks:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Task description</th>
      <th>Size</th>
      <th>Metrics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cola</th>
      <td>Corpus of Linguistic Acceptability</td>
      <td>Determine whether it is a grammatical sentence</td>
      <td>8.5k</td>
      <td>matthews_corrcoef</td>
    </tr>
    <tr>
      <th>sst2</th>
      <td>Stanford Sentiment Treebank</td>
      <td>Predict the sentiment of a givensentence</td>
      <td>67k</td>
      <td>accuracy</td>
    </tr>
    <tr>
      <th>mrpc</th>
      <td>Microsoft Research Paraphrase Corpus</td>
      <td>Determine whether the sentences in the pair are semantically equivalent</td>
      <td>3.7k</td>
      <td>f1/accuracy</td>
    </tr>
    <tr>
      <th>stsb</th>
      <td>Semantic Textual Similarity Benchmark</td>
      <td>Determine similarity score for 2 sentences</td>
      <td>7k</td>
      <td>pearsonr/spearmanr</td>
    </tr>
    <tr>
      <th>qqp</th>
      <td>Quora question pair</td>
      <td>Determine if 2 questions are the same (paraphrase)</td>
      <td>364k</td>
      <td>f1/accuracy</td>
    </tr>
    <tr>
      <th>mnli</th>
      <td>Mulit-Genre Natural Language Inference</td>
      <td>Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>
      <td>393k</td>
      <td>accuracy</td>
    </tr>
    <tr>
      <th>qnli</th>
      <td>Stanford Question Answering Dataset</td>
      <td>Determine whether the context sentence containsthe answer to the question</td>
      <td>105k</td>
      <td>accuracy</td>
    </tr>
    <tr>
      <th>rte</th>
      <td>Recognize Textual Entailment</td>
      <td>Determine whether one sentece entails another</td>
      <td>2.5k</td>
      <td>accuracy</td>
    </tr>
    <tr>
      <th>wnli</th>
      <td>Winograd Schema Challenge</td>
      <td>Predict if the sentence with the pronoun substituted is entailed by the original sentence</td>
      <td>634</td>
      <td>accuracy</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's define main settings for the run in one place. You can choose any model from wide variety presented in HuggingFace model hub. Some might need special treatment to work but most models of appropriate class should be plug-and-play.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds_name</span> <span class="o">=</span> <span class="s1">&#39;glue&#39;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;distilroberta-base&quot;</span>

<span class="n">max_len</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">bs</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">val_bs</span> <span class="o">=</span> <span class="n">bs</span><span class="o">*</span><span class="mi">2</span>

<span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">opt_func</span> <span class="o">=</span> <span class="n">Adam</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To make switching between datasets smooth I'll define couple of dictionaries containing per-task information. We'll need metrics, text fields to retrieve data and number of outputs for the model.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">GLUE_TASKS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cola&quot;</span><span class="p">,</span> <span class="s2">&quot;mnli&quot;</span><span class="p">,</span> <span class="s2">&quot;mrpc&quot;</span><span class="p">,</span> <span class="s2">&quot;qnli&quot;</span><span class="p">,</span> <span class="s2">&quot;qqp&quot;</span><span class="p">,</span> <span class="s2">&quot;rte&quot;</span><span class="p">,</span> <span class="s2">&quot;sst2&quot;</span><span class="p">,</span> <span class="s2">&quot;stsb&quot;</span><span class="p">,</span> <span class="s2">&quot;wnli&quot;</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">validate_task</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">GLUE_TASKS</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">glue_metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;cola&#39;</span><span class="p">:[</span><span class="n">MatthewsCorrCoef</span><span class="p">()],</span>
    <span class="s1">&#39;sst2&#39;</span><span class="p">:[</span><span class="n">accuracy</span><span class="p">],</span>
    <span class="s1">&#39;mrpc&#39;</span><span class="p">:[</span><span class="n">F1Score</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">],</span>
    <span class="s1">&#39;stsb&#39;</span><span class="p">:[</span><span class="n">PearsonCorrCoef</span><span class="p">(),</span> <span class="n">SpearmanCorrCoef</span><span class="p">()],</span>
    <span class="s1">&#39;qqp&#39;</span> <span class="p">:[</span><span class="n">F1Score</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">],</span>
    <span class="s1">&#39;mnli&#39;</span><span class="p">:[</span><span class="n">accuracy</span><span class="p">],</span>
    <span class="s1">&#39;qnli&#39;</span><span class="p">:[</span><span class="n">accuracy</span><span class="p">],</span>
    <span class="s1">&#39;rte&#39;</span> <span class="p">:[</span><span class="n">accuracy</span><span class="p">],</span>
    <span class="s1">&#39;wnli&#39;</span><span class="p">:[</span><span class="n">accuracy</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">glue_textfields</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;cola&#39;</span><span class="p">:[</span><span class="s1">&#39;sentence&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="s1">&#39;sst2&#39;</span><span class="p">:[</span><span class="s1">&#39;sentence&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="s1">&#39;mrpc&#39;</span><span class="p">:[</span><span class="s1">&#39;sentence1&#39;</span><span class="p">,</span> <span class="s1">&#39;sentence2&#39;</span><span class="p">],</span>
    <span class="s1">&#39;stsb&#39;</span><span class="p">:[</span><span class="s1">&#39;sentence1&#39;</span><span class="p">,</span> <span class="s1">&#39;sentence2&#39;</span><span class="p">],</span>
    <span class="s1">&#39;qqp&#39;</span> <span class="p">:[</span><span class="s1">&#39;question1&#39;</span><span class="p">,</span> <span class="s1">&#39;question2&#39;</span><span class="p">],</span>
    <span class="s1">&#39;mnli&#39;</span><span class="p">:[</span><span class="s1">&#39;premise&#39;</span><span class="p">,</span> <span class="s1">&#39;hypothesis&#39;</span><span class="p">],</span>
    <span class="s1">&#39;qnli&#39;</span><span class="p">:[</span><span class="s1">&#39;question&#39;</span><span class="p">,</span> <span class="s1">&#39;sentence&#39;</span><span class="p">],</span>
    <span class="s1">&#39;rte&#39;</span> <span class="p">:[</span><span class="s1">&#39;sentence1&#39;</span><span class="p">,</span> <span class="s1">&#39;sentence2&#39;</span><span class="p">],</span>
    <span class="s1">&#39;wnli&#39;</span><span class="p">:[</span><span class="s1">&#39;sentence1&#39;</span><span class="p">,</span> <span class="s1">&#39;sentence2&#39;</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">glue_num_labels</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;mnli&#39;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;stsb&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-preprocessing">Data preprocessing<a class="anchor-link" href="#Data-preprocessing"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll be using <code>datasets</code> library for HuggingFace to get data:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="s1">&#39;mrpc&#39;</span><span class="p">;</span> <span class="n">validate_task</span><span class="p">()</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">ds_name</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>MNLI datasets contains 2 sets for validation: matched and missmatched. The mathced set is selected here for validation when fine-tuning on MNLI.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_</span> <span class="o">=</span> <span class="s1">&#39;validation-matched&#39;</span> <span class="k">if</span> <span class="n">task</span><span class="o">==</span><span class="s1">&#39;mnli&#39;</span> <span class="k">else</span> <span class="s1">&#39;validation&#39;</span>
<span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="n">valid_</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(3668, 408)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nt</span><span class="p">,</span> <span class="n">nv</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="n">valid_</span><span class="p">])</span>
<span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nt</span><span class="p">)),</span> <span class="n">L</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nt</span><span class="p">,</span> <span class="n">nt</span><span class="o">+</span><span class="n">nv</span><span class="p">))</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">concatenate_datasets</span><span class="p">([</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">ds</span><span class="p">[</span><span class="n">valid_</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One can inspect single example for the given task:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_ds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;idx&#39;: 0,
 &#39;label&#39;: 1,
 &#39;sentence1&#39;: &#39;Amrozi accused his brother , whom he called &#34; the witness &#34; , of deliberately distorting his evidence .&#39;,
 &#39;sentence2&#39;: &#39;Referring to him as only &#34; the witness &#34; , Amrozi accused his brother of deliberately distorting his evidence .&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here I use number of characters a proxy for length of tokenized text to speed up <code>dls</code> creation.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lens</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;len&#39;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">glue_textfields</span><span class="p">[</span><span class="n">task</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span><span class="p">])},</span>
                    <span class="n">remove_columns</span><span class="o">=</span><span class="n">train_ds</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="n">num_proc</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keep_in_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_lens</span> <span class="o">=</span> <span class="n">lens</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)[</span><span class="s1">&#39;len&#39;</span><span class="p">]</span>
<span class="n">valid_lens</span> <span class="o">=</span> <span class="n">lens</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)[</span><span class="s1">&#39;len&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="DataBlock-and-Transforms">DataBlock and Transforms<a class="anchor-link" href="#DataBlock-and-Transforms"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>TextGetter</code> is analogous to <a href="https://docs.fast.ai/data.transforms#ItemGetter"><code>ItemGetter</code></a> but retrieves either one or two text fields from the source (e.g. "sentence1" and "sentence2").</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TextGetter</span><span class="p">(</span><span class="n">ItemTransform</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s1</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s2</span> <span class="o">=</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span>
    <span class="k">def</span> <span class="nf">encodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">s2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="k">return</span> <span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">s2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Transformers expect two parts of text to be concatenated with some <code>SEP</code> token in between. But when displaying the batch it's better to have those texts in separate columns for better readability. To make it work I define a version of <code>show_batch</code> to be dispatched on the <code>TransTensorText</code> class. It will handle cases when there is single decoded text or a tuple of two texts.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TransTensorText</span><span class="p">(</span><span class="n">TensorBase</span><span class="p">):</span> <span class="k">pass</span>

<span class="nd">@typedispatch</span>
<span class="k">def</span> <span class="nf">show_batch</span><span class="p">(</span><span class="n">x</span><span class="p">:</span><span class="n">TransTensorText</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">ctxs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ctxs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">ctxs</span> <span class="o">=</span> <span class="n">get_empty_df</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">max_n</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trunc_at</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">trunc_at</span><span class="p">),</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">trunc_at</span><span class="p">),</span> <span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">trunc_at</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">trunc_at</span><span class="p">),</span><span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">)</span>
    <span class="n">ctxs</span> <span class="o">=</span> <span class="n">show_batch</span><span class="p">[</span><span class="nb">object</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="n">max_n</span><span class="p">,</span> <span class="n">ctxs</span><span class="o">=</span><span class="n">ctxs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">display_df</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">ctxs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary data-open="Hide Code" data-close="Show Code"></summary>
        <summary></summary>
        <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">find_first</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">v</span> <span class="o">==</span> <span class="n">e</span><span class="p">:</span> <span class="k">return</span> <span class="n">i</span>
        
<span class="k">def</span> <span class="nf">split_by_sep</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sep_tok_id</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">find_first</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sep_tok_id</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">t</span><span class="p">[:</span><span class="n">idx</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="n">idx</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Tokenization of the inputs will be done by <code>TokBatchTransform</code> which wraps pre-trained HuggingFace tokenizer. The text processing is done in batches for speed-up. We want to awoid explicit python loops when possible.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TokBatchTransform</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenizes texts in batches using pretrained HuggingFace tokenizer.</span>
<span class="sd">    The first element in a batch can be single string or 2-tuple of strings.</span>
<span class="sd">    If `with_labels=True` the &quot;labels&quot; are added to the output dictionary.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pretrained_model_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer_cls</span><span class="o">=</span><span class="n">AutoTokenizer</span><span class="p">,</span> 
                 <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer_cls</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_two_texts</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">store_attr</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">encodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># batch is a list of tuples of ({text or (text1, text2)}, {targets...})</span>
        <span class="k">if</span> <span class="n">is_listy</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]):</span> <span class="c1"># 1st element is tuple</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_two_texts</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">is_listy</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span> 
            <span class="n">texts</span> <span class="o">=</span> <span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],)</span>

        <span class="n">inps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="o">*</span><span class="n">texts</span><span class="p">,</span>
                              <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
                              <span class="n">truncation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">truncation</span><span class="p">,</span>
                              <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
                              <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span>
                              <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># inps are batched, collate targets into batches too</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">default_collate</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_labels</span><span class="p">:</span>
            <span class="n">inps</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">inps</span><span class="p">,</span> <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">inps</span><span class="p">,</span> <span class="p">)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>
    
    <span class="k">def</span> <span class="nf">decodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">TransTensorText</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_two_texts</span><span class="p">:</span>
            <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">split_by_sep</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">TitledStr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
                    <span class="n">TitledStr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x2</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">TitledStr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The batches processed by <code>TokBatchTransform</code> contain a dictionary as the first element. For decoding it's handy to have a tensor instead. The <code>Undict</code> transform fethces <code>input_ids</code> from the batch and creates <code>TransTensorText</code> which should work with typedispatch.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Undict</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">decodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="nb">dict</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;input_ids&#39;</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span> <span class="n">res</span> <span class="o">=</span> <span class="n">TransTensorText</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now the transforms are to be combined inside a data block to be used for <code>dls</code> creation. The inputs are prebatched by <code>TokBatchTranform</code> so we don't need to use <a href="https://docs.fast.ai/data.load#fa_collate"><code>fa_collate</code></a> for batching, so <a href="https://docs.fast.ai/data.load#fa_convert"><code>fa_convert</code></a> is passed in as for "create_batch".</p>
<p>The texts we processing are of different lengths. Each sample in the batch is padded to the length of longest input to make them "collatable". Shuffling samples randomly will therefor result in getting longer batches on average. As the compute time depends on the sequence length this is udesired. <a href="https://docs.fast.ai/text.data#SortedDL"><code>SortedDL</code></a> groups the inputs by length and if <code>shuffle=True</code> those are shuffled within certain interval keeping samples of similar length together.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;before_batch&#39;</span><span class="p">:</span> <span class="n">TokBatchTransform</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">),</span>
    <span class="s1">&#39;create_batch&#39;</span><span class="p">:</span> <span class="n">fa_convert</span>
<span class="p">}</span>
<span class="n">text_block</span> <span class="o">=</span> <span class="n">TransformBlock</span><span class="p">(</span><span class="n">dl_type</span><span class="o">=</span><span class="n">SortedDL</span><span class="p">,</span> <span class="n">dls_kwargs</span><span class="o">=</span><span class="n">dls_kwargs</span><span class="p">,</span> <span class="n">batch_tfms</span><span class="o">=</span><span class="n">Undict</span><span class="p">(),</span> <span class="p">)</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span> <span class="o">=</span> <span class="p">[</span><span class="n">text_block</span><span class="p">,</span> <span class="n">CategoryBlock</span><span class="p">()],</span>
                   <span class="n">get_x</span><span class="o">=</span><span class="n">TextGetter</span><span class="p">(</span><span class="o">*</span><span class="n">glue_textfields</span><span class="p">[</span><span class="n">task</span><span class="p">]),</span>
                   <span class="n">get_y</span><span class="o">=</span><span class="n">ItemGetter</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">),</span>
                   <span class="n">splitter</span><span class="o">=</span><span class="n">IndexSplitter</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
dl_kwargs=[{&#39;res&#39;:train_lens}, {&#39;val_res&#39;:valid_lens}]
dls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs, dl_kwargs=dl_kwargs)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 2.92 s, sys: 858 ms, total: 3.78 s
Wall time: 3.79 s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>text_</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The Securities and Exchange Commission yesterday said companies trading on the biggest U.S. markets must win shareholder approval before granting stock options and other stock-based compensation plans to corporate executives.</td>
      <td>Companies trading on the biggest stock markets must get shareholder approval before granting stock options and other equity compensation under rules cleared yesterday by the Securities and Exchange Commission.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>" The investigation appears to be focused on certain accounting practices common to the interactive entertainment industry, with specific emphasis on revenue recognition, " Activision said in an SEC filing.</td>
      <td>According to the company filings, the investigation " appears to be focused on certain accounting practices common to the interactive entertainment industry, with specific emphasis on revenue recognition. "</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The U.N. nuclear watchdog reprimanded Iran on Thursday for failing to comply with its nuclear safeguards obligations and called on Tehran to unconditionally accept stricter inspections by the agency.</td>
      <td>The U.N. atomic watchdog rapped Iran Thursday for failing to comply with nuclear safeguards, issuing a statement Washington said underlined international opposition to Tehran developing any banned weapons.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Microsoft favors setting up " independent e-mail trust authorities to establish and maintain commercial email guidelines, certify senders who follow the guidelines, and resolve customer disputes. "</td>
      <td>Gates says he wants to see " independent e-mail trust authorities " who " establish and maintain commercial email guidelines, certify senders who follow the guidelines, and resolve customer disputes. "</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Customized-Learner">Customized Learner<a class="anchor-link" href="#Customized-Learner"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now the <code>xb</code> we get from dataloader contains a dictionary and HuggingFace transformers accept keyword argument as input. But fastai <a href="https://docs.fast.ai/learner#Learner"><code>Learner</code></a> feeds the model with a sequence of positional arguments (<code>self.pred = self.model(*self.xb)</code>). To make this work smoothly we can create a callback to handle unrolling of the input dict into proper <code>xb</code> tuple.</p>
<p>But first we need to define some utility functions. <code>default_splitter</code> is used to divide model parameters into groups:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">default_splitter</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">children</span><span class="p">())</span> <span class="o">+</span> <span class="n">L</span><span class="p">(</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">children</span><span class="p">())[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">if</span> <span class="n">params</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">groups</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similar to <code>show_batch</code> one have to customize <code>show_results</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@typedispatch</span>
<span class="k">def</span> <span class="nf">show_results</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">TransTensorText</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">outs</span><span class="p">,</span> <span class="n">ctxs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ctxs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">ctxs</span> <span class="o">=</span> <span class="n">get_empty_df</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">max_n</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trunc_at</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">trunc_at</span><span class="p">),</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">trunc_at</span><span class="p">),</span> <span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trunc_at</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">trunc_at</span><span class="p">),</span><span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">)</span>
    <span class="n">ctxs</span> <span class="o">=</span> <span class="n">show_results</span><span class="p">[</span><span class="nb">object</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">outs</span><span class="p">,</span> <span class="n">ctxs</span><span class="o">=</span><span class="n">ctxs</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="n">max_n</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">display_df</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">ctxs</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">ctxs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>TransLearner</code> itself doesn't do much: it adds <code>TransCallback</code> and sets <code>splitter</code> to be <code>default_splitter</code> if <code>None</code> is provided.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@delegates</span><span class="p">(</span><span class="n">Learner</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TransLearner</span><span class="p">(</span><span class="n">Learner</span><span class="p">):</span>
    <span class="s2">&quot;Learner for training transformers from HuggingFace&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">splitter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;splitter&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">splitter</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;splitter&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">default_splitter</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">TransCallback</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Main piece of work needed to train transformers model happens in <code>TransCallback</code>. It saves valid model argument and makes input dict yielded by dataloader into a tuple.</p>
<p>By default the model returns a dictionary-like object containing <code>logits</code> and possibly other outputs as defined by model config (e.g. intermediate hidden representations). In the fastai training loop we usually expect <code>preds</code> to be a tensor containing model predictions (logits). The callback formats the preds properly.</p>
<p>Notice that if <code>labels</code> are found in the input, transformer models compute the <code>loss</code> and return it together with output <code>logits</code>. The callback below is designed to utilise the loss returned by model instead of recomputing it using <code>learn.loss_func</code>. This is not actually used in this example but might be handy in some use cases.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TransCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="s2">&quot;Handles HuggingFace model inputs and outputs&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_args</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span><span class="o">.</span><span class="n">default</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">signature</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    
    <span class="k">def</span> <span class="nf">before_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;labels&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">xb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xb</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;labels&#39;</span><span class="p">],</span> <span class="p">)</span>
        <span class="c1"># make a tuple containing an element for each argument model excepts</span>
        <span class="c1"># if argument is not in xb it is set to default value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">xb</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">xb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_args</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_args</span><span class="o">.</span><span class="n">keys</span><span class="p">()])</span>
    
    <span class="k">def</span> <span class="nf">after_pred</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;loss&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">loss_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">logits</span>
    
    <span class="k">def</span> <span class="nf">after_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">yb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training">Training<a class="anchor-link" href="#Training"> </a></h2><p>After all the preparations the training is streightforward. Setting <code>num_labels</code> for the model and choosing apropriate metrics is automated.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">glue_num_labels</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">glue_metrics</span><span class="p">[</span><span class="n">task</span><span class="p">]</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">TransLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">opt_func</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary data-open="Hide Output" data-close="Show Output"></summary>
        <summary></summary>
        
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>RobertaForSequenceClassification (Input shape: 32)
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     32 x 101 x 768      
Embedding                                 38603520   True      
Embedding                                 394752     True      
Embedding                                 768        True      
LayerNorm                                 1536       True      
Dropout                                                        
Linear                                    590592     True      
Linear                                    590592     True      
Linear                                    590592     True      
Dropout                                                        
Linear                                    590592     True      
LayerNorm                                 1536       True      
Dropout                                                        
____________________________________________________________________________
                     32 x 101 x 3072     
Linear                                    2362368    True      
____________________________________________________________________________
                     32 x 101 x 768      
Linear                                    2360064    True      
LayerNorm                                 1536       True      
Dropout                                                        
Linear                                    590592     True      
Linear                                    590592     True      
Linear                                    590592     True      
Dropout                                                        
Linear                                    590592     True      
LayerNorm                                 1536       True      
Dropout                                                        
____________________________________________________________________________
                     32 x 101 x 3072     
Linear                                    2362368    True      
____________________________________________________________________________
                     32 x 101 x 768      
Linear                                    2360064    True      
LayerNorm                                 1536       True      
Dropout                                                        
Linear                                    590592     True      
Linear                                    590592     True      
Linear                                    590592     True      
Dropout                                                        
Linear                                    590592     True      
LayerNorm                                 1536       True      
Dropout                                                        
____________________________________________________________________________
                     32 x 101 x 3072     
Linear                                    2362368    True      
____________________________________________________________________________
                     32 x 101 x 768      
Linear                                    2360064    True      
LayerNorm                                 1536       True      
Dropout                                                        
Linear                                    590592     True      
Linear                                    590592     True      
Linear                                    590592     True      
Dropout                                                        
Linear                                    590592     True      
LayerNorm                                 1536       True      
Dropout                                                        
____________________________________________________________________________
                     32 x 101 x 3072     
Linear                                    2362368    True      
____________________________________________________________________________
                     32 x 101 x 768      
Linear                                    2360064    True      
LayerNorm                                 1536       True      
Dropout                                                        
Linear                                    590592     True      
Linear                                    590592     True      
Linear                                    590592     True      
Dropout                                                        
Linear                                    590592     True      
LayerNorm                                 1536       True      
Dropout                                                        
____________________________________________________________________________
                     32 x 101 x 3072     
Linear                                    2362368    True      
____________________________________________________________________________
                     32 x 101 x 768      
Linear                                    2360064    True      
LayerNorm                                 1536       True      
Dropout                                                        
Linear                                    590592     True      
Linear                                    590592     True      
Linear                                    590592     True      
Dropout                                                        
Linear                                    590592     True      
LayerNorm                                 1536       True      
Dropout                                                        
____________________________________________________________________________
                     32 x 101 x 3072     
Linear                                    2362368    True      
____________________________________________________________________________
                     32 x 101 x 768      
Linear                                    2360064    True      
LayerNorm                                 1536       True      
Dropout                                                        
Linear                                    590592     True      
Dropout                                                        
____________________________________________________________________________
                     32 x 2              
Linear                                    1538       True      
____________________________________________________________________________

Total params: 82,119,938
Total trainable params: 82,119,938
Total non-trainable params: 0

Optimizer used: &lt;function Adam at 0x7fa9069c1268&gt;
Loss function: FlattenedLoss of CrossEntropyLoss()

Callbacks:
  - TrainEvalCallback
  - TransCallback
  - Recorder
  - ProgressCallback</pre>
</div>

</div>

</div>
</div>

    </details>
</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">metric_to_monitor</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Metric</span><span class="p">)</span> <span class="k">else</span> <span class="n">metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="vm">__name__</span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">SaveModelCallback</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="n">metric_to_monitor</span><span class="p">)]</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>f1_score</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.599429</td>
      <td>0.508199</td>
      <td>0.832551</td>
      <td>0.737745</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.436955</td>
      <td>0.337732</td>
      <td>0.892193</td>
      <td>0.857843</td>
      <td>00:22</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.318495</td>
      <td>0.331339</td>
      <td>0.900175</td>
      <td>0.860294</td>
      <td>00:22</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.232149</td>
      <td>0.354381</td>
      <td>0.897747</td>
      <td>0.855392</td>
      <td>00:22</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Better model found at epoch 0 with f1_score value: 0.8325508607198748.
Better model found at epoch 1 with f1_score value: 0.8921933085501859.
Better model found at epoch 2 with f1_score value: 0.9001751313485115.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After training the model it's useful to verify  that results make sense:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>text_</th>
      <th>category</th>
      <th>category_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The delegates said raising and distributing funds has been complicated by the U.S. crackdown on jihadi charitable foundations, bank accounts of terror-related organizations and money transfers.</td>
      <td>Bin Laden  s men pointed out that raising and distributing funds has been complicated by the U.S. crackdown on jihadi charitable foundations, bank accounts of terror-related organizations and money transfers.</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The attack followed several days of disturbances in the city where American soldiers exchanged fire with an unknown number of attackers as civilians carried out demonstrations against the American presence.</td>
      <td>The attack came after several days of disturbance in the city in which U.S. soldiers exchanged fire with an unknown number of attackers as civilians protested the American presence.</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Massachusetts regulators and the Securities and Exchange Commission on Tuesday pressed securities fraud charges against Putnam Investments and two of its former portfolio managers for alleged improper mutual fund trading.</td>
      <td>State and federal securities regulators filed civil charges against Putnam Investments and two portfolio managers in the ever-expanding mutual fund trading scandal.</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Justice Minister Martin Cauchon and Prime Minister Jean Chrtien have both said the Liberal government will introduce legislation soon to decriminalize possession of small amounts of pot for personal use.</td>
      <td>Justice Minister Martin Cauchon and Prime Minister Jean Chretien both have said the government will introduce legislation to decriminalize possession of small amounts of pot.</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Myanmar's pro-democracy leader Aung San Suu Kyi will return home late Friday but will remain in detention after recovering from surgery at a Yangon hospital, her personal physician said.</td>
      <td>Myanmar's pro-democracy leader Aung San Suu Kyi will be kept under house arrest following her release from a hospital where she underwent surgery, her personal physician said Friday.</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>President Bush raised a record-breaking $ 49.5 million for his re-election campaign over the last three months, with contributions from 262,000 Americans, the president's campaign chairman said Tuesday.</td>
      <td>President Bush has raised $ 83.9 million since beginning his re-election campaign in May, and has $ 70 million of that left to spend, his campaign said Tuesday.</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Barry Callebaut will be able to use Brach's retail network to sell products made from its German subsidiary Stollwerck, which makes chocolate products not sold in the United States.</td>
      <td>Barry Callebaut will be able to use Brach's retail network to sell products made from its German subsidiary Stollwerck, which makes chocolate products unknown to the American market.</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Donations stemming from the Sept. 11 attacks helped push up contributions to human service organizations and large branches of the United Way by 15 percent and 28.6 percent, respectively.</td>
      <td>Donations stemming from the Sept. 11 attacks helped push up contributions to human service organizations by 15 percent and to large branches of the United Way by 28.6 percent.</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>The Guru microcontroller serves four functions : hardware monitoring, overclocking management, BIOS ( Basic Input Output System ) update and a troubleshooting-assistance feature called Black Box.</td>
      <td>The Guru microcontroller serves four functions : hardware monitoring, overclocking management, BIOS update and a troubleshooting-assistance feature called Black Box.</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we can run our model on test set to get the predictions.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_dl</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">test_dl</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">dl</span><span class="o">=</span><span class="n">test_dl</span><span class="p">)</span>
<span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.0121, 0.9879],
        [0.1296, 0.8704],
        [0.0072, 0.9928],
        ...,
        [0.0159, 0.9841],
        [0.0046, 0.9954],
        [0.1612, 0.8388]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Final-remarks">Final remarks<a class="anchor-link" href="#Final-remarks"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Generalised versions of "wrapper" code used in this notebook can be found in <a href="https://github.com/aikindergarten/fasthugs">fasthugs</a> library. Also you can check out some extra info on fine-tuning models on GLUE tasks in <a href="https://arampacha.github.io/thoughtsamples/fastai/huggingface/transformers/2021/05/07/glue-benchmark.html">this blogpost</a>. Another option for training HuggingFace transformers with fastai is using <a href="https://github.com/ohmeow/blurr">blurr</a> library.</p>

</div>
</div>
</div>
</div>
 

